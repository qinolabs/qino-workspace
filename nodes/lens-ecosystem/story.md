How lens technology crosses from infrastructure into living modality experience — Journey as nervous system routing sensitivity, modalities as organs generating their own content, Lens Lab as laboratory surface.

**Territory**: Journey voicing infrastructure + modality integration patterns (World, Walk) + Lens Lab calibration + lens concept architecture
**Since**: 2026-02-09

**What sparked this**: Building Infra 09 (Ecosystem Calibration) and running two validation builds that revealed the nervous system boundary. Walk forced its data into Journey's substrate shape — proving the runtime API conflated ecosystem-level and modality-local operations. The boundary sharpened the metaphor: Journey carries sensitivity, organs generate experience.

**Key evolution (2026-02-10)**: The Infra 09 runtime API surface was removed entirely — zero consumers across all modalities. The nervous system metaphor survived but the implementation model flipped: Journey operates through **calibration propagation** (lens versions → cache invalidation → different perception), not runtime API calls. The calibration vocabulary remains (`SlotType`, `selectLens` cascade, `LensContext` extensions).

**Sibling**: `emergence-experiments` — that navigator maps what emerges (readiness, awakening, accumulation mechanics). This one maps how sensitivity reaches the organs (lens integration, calibration propagation, the grammar that adapts vocabulary across modalities).

**Key evolution (2026-02-16)**: Natural mention detection (Layer 1 Jaro-Winkler + Layer 2 extraction piggyback) provides the live entry point for substrate accumulation. The mention-to-substrate-to-awakening chain is no longer dead code — users reference mentions naturally in conversation and the system detects it. Model tier consolidated to 4 tiers (CREATIVE, ANALYTICAL, DIALOGUE, STRUCTURED); lens-lab and emergence-lab assessment services migrated to `@qinolabs/ai` with ANALYTICAL tier at 75-97% cost reduction.

**The open frontier**: The vocabulary is built (24 lenses, 8 slot types, calibration via version-based cache invalidation). The working pipeline (`voiceFigureWithData`, `selectLens` cascade) handles crossing voicing. Substrate now accumulates through natural mention detection, shifting the key question from "how do we get substrate?" to "does accumulated substrate produce divergent lens readings across user profiles?" Three tracks:
1. **Deepen what works** — World 23 (inline crossing), Walk 16 phases 4-5 (planning layer)
2. **Expand the laboratory** — Lens Lab 23 (relational lenses, world fixtures, crossing simulation)
3. **Validate the chain** — longer simulation runs (15+ turns) testing mention-to-substrate-to-awakening with divergent user profiles