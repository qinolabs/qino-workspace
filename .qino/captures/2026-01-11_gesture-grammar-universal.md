# Gesture Grammar: Modality â†’ Universal

**Captured:** 2026-01-11

We likely need **two levels of gesture grammar**:

- **Modality-specific grammar**: gestures interpreted within a surface (chat, world map, walk, session preview, etc.). Each modality can introduce its own verbs and constraints.
- **Ecosystem/universal grammar**: a shared, composable vocabulary of intent patterns that modality-level gestures translate into.

What starts as modality-specific should have a clear path to evolve into universal grammar as patterns repeat across surfaces.

This ties directly to:
- **ecosystem-domain-language** (shared vocabulary across apps)
- **qino-claude tool grammar** (command namespaces as structured vocabulary that can compose into a universal grammar)

Implication: gestures are not just UI interactions; they are **intent translators** into a shared grammar that can grow with the ecosystem.
